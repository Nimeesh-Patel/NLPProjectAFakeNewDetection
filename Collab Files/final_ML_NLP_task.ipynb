{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nimeesh-Patel/NLPProjectAFakeNewDetection/blob/main/Collab%20Files/final_ML_NLP_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GtfdwiXbN9DR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fake New Detection\n",
        "\n",
        "\n",
        "\n",
        "1.   Abhinav Nair 636\n",
        "2.   Mannat Nayyar 639\n",
        "3.   Nimeesh Patel 643\n",
        "2.   Aditya V. Patil 645"
      ],
      "metadata": {
        "id": "cAQ3MbHVN-ia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 1: Load the Dataset**"
      ],
      "metadata": {
        "id": "mfXF5t-7c8qc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "du9sw0BJQUYH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2e5b9372-ce87-49b1-d68d-5dcb16483365"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  label\n",
              "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1\n",
              "1  Ever get the feeling your life circles the rou...      0\n",
              "2  Why the Truth Might Get You Fired October 29, ...      1\n",
              "3  Videos 15 Civilians Killed In Single US Airstr...      1\n",
              "4  Print \\nAn Iranian woman has been sentenced to...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f33f87b3-1154-4deb-9847-a719e3fdc27e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f33f87b3-1154-4deb-9847-a719e3fdc27e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f33f87b3-1154-4deb-9847-a719e3fdc27e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f33f87b3-1154-4deb-9847-a719e3fdc27e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d55091fd-291f-45d5-9b1e-6c17d3b46db6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d55091fd-291f-45d5-9b1e-6c17d3b46db6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d55091fd-291f-45d5-9b1e-6c17d3b46db6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 985,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 982,\n        \"samples\": [\n          \"Perhaps you\\u2019ve heard the saying, \\u201cYou can\\u2019t make this stuff up. \\u201d So, so wrong. It turns out the subway cricket lady was a prank. The   subway riders? Flimflam. Even, it seems, that      New Yorker the Pizza Rat may have been schooled and rehearsed for the camera. Is no crazy thing sacred, or at least genuine? The subway cricket lady, for those not paying attention, was videotaped last week on the D train as she was supposedly trying to sell crickets and worms out of a bucket. As the story went, a group of teenagers bumped into her and she flew off the handle and dumped the crickets and worms into the train. \\u201cStraphangers Go Berserk After Woman Tosses Bugs in Subway Car,\\u201d The New York Post reported. The emergency brake was pulled  \\u2014   a truly useless maneuver, bringing the train to a dead stop on the Manhattan Bridge. The first reports of this were accompanied by a cellphone video of the chaos. Then another video surfaced and the   reporters Rafi Schwartz and Soraya Auger of Vox noticed that it was quite a polished bit of filmmaking. Through advanced interrogation techniques, they extracted an admission of responsibility from the woman who posted it. She declared herself to be the   and said she was engaged in performance art having something to do with homelessness. The bucket of bugs was knocked out of her hands by another member of her troupe. Who knows how many other passengers were part of the staging or just fated to be along for the ride. Eventually, the brakes were reset and the train moved off the bridge. On Tuesday, having been exposed, she was arrested on a charge of reckless endangerment by the police, who had previously been willing to let her slide. So actually, you can make this stuff up, and be believed. But why bother? The implausible is the daily bread of the subway, served without irony. Real events: Trysts. Preachers. Makeup artists. The \\u201c    \\u201d acrobats. Buckets of dead crabs, as Gothamist reported, and a condom tied to a pole on the F train, apparently for weeks, and seemingly, we regret to say,  . All manner of live creatures: chickens, frogs, goldfish, cats, a monkey. And of course, microbes, by the kajillion. (The Central Intelligence Agency took it upon itself in 1966 to see how quickly germs would be propelled through the tunnels via the piston effect of moving trains. At strategic spots, the C. I. A. people dropped light bulbs filled with what they termed innocuous bacteria, then measured how far they traveled.) Then there is the snake guy. \\u201cHe wasn\\u2019t talking at all,\\u201d Conor C. Walsh remembered. \\u201cHe had an intern, a young kid helper, and a duffel bag filled with five or six snakes. \\u201d It was Halloween night two years ago, and Mr. Walsh and some friends were on a train that was moseying to Williamsburg. At first, the man draped the snakes on an overhead handrail. Then he walked through the car with them. \\u201cUnless you really protested, he was putting them on people,\\u201d Mr. Walsh, 28, said. \\u201cThere was a   woman shrieking and screaming. He wasn\\u2019t going to put it on her. \\u201d Some of the passengers seemed thrilled about having a snake coiled around their bodies. \\u201cI don\\u2019t like them at all,\\u201d Mr. Walsh said. \\u201cIt\\u2019s my one thing. I kept him away, at all times. I was just imagining his apartment, or his warehouse, wherever he kept them. \\u201d Although the man did not speak, he appeared to be marketing the snakes. \\u201cHe had business cards that he passed out,\\u201d Mr. Walsh said, \\u201cbut no one was walking away with a snake. \\u201d Mr. Walsh, who grew up in New York and teaches high school in Windsor Terrace, Brooklyn, is also a singer and guitarist with the indie band  . He has put subway exotica to excellent use in his music. \\u201cThere are days when you hate the subways and days when you meet some awesome people,\\u201d he said. \\u201cI sat down next to this guy one time, and we got talking, so I asked him what he did. He said: \\u2018I\\u2019m a shaman. I\\u2019m an actual shaman. I help my clients speak to the spirits.\\u2019 He was a nice kid, 26. Had gone to Hampshire, that college in Massachusetts. \\u201d Mr. Walsh turned his encounter with the young shaman into a brisk, fun pop tune, \\u201cShaman,\\u201d which begins: \\u201cI met a shaman who grew up in Queens   On the D train his knees touching me. \\u201d After all, there\\u2019s magical realism to spare.\",\n          \"Schools All Over America Are Closing On Election Day Due To Fears Of Violence   \\nWill this be the most chaotic election day in modern American history? All across the nation, schools are being closed on election day due to safety fears. Traditionally, schools have been very popular as voting locations because they can accommodate a lot of people, they usually have lots of parking, and everyone in the community knows where they are and can usually get to them fairly easily. But now there is a big movement to remove voting from schools or to shut schools down on election day so that children are not present when voting takes place. According to Fox News , \\u201cvoting has been removed or classes have been canceled on Election Day at schools in Illinois, Maine, Nebraska, New Hampshire, Ohio, Pennsylvania, Wisconsin and elsewhere.\\u201d Just a couple days ago , I shared with you a survey that found that 51 percent of all Americans are concerned about violence happening on election day, and all of these schools closing is just another sign of how on edge much of the population is as we approach November 8th. \\nMany officials are being very honest about the fact that schools are being shut down on election day because they are afraid of election violence. The following comes from Fox News \\u2026 \\nSeveral schools across the nation have decided to close on Election Day over fears of possible violence in the hallways stemming from the fallout from the heated rhetoric that consumed the campaign trail. \\nThe fear is the ugliness of the election season could escalate into confrontations and even violence in the school hallways, endangering students. \\n\\u201cIf anybody can sit there and say they don\\u2019t think this is a contentious election, then they aren\\u2019t paying much attention,\\u201d Ed Tolan, the Falmouth, Maine police chief, said Tuesday. His community has already called off classes on Nov. 8 and an increased police presence will be felt around town. \\nAnd without a doubt, voting locations are \\u201csoft targets\\u201d that often have little or no security. We have been blessed to have had such peaceful elections in the past, but we also need to realize that times have changed. I believe that there is wisdom in what Georgia Secretary of State Brian Kemp told reporters \\u2026 \\n\\u201cThere is a concern, just like at a concert, sporting event or other public gathering that we didn\\u2019t have 15 or 20 years ago,\\u201d said Georgia Secretary of State Brian Kemp, co-chairman of the National Association of Secretaries of State election committee. \\u201c What if someone walks in a polling location with a backpack bomb or something? If that happens at a school, then that\\u2019s certainly concerning.\\u201d \\nAll it is going to take is a single incident to change everything. \\nLet us hope that it is not this election day when we see something like that. \\nAnother reason why polling locations are under increased scrutiny this election season is because of concerns about election fraud. This is something that Donald Trump has alluded to repeatedly on the campaign trail. For instance, just consider what he told a rally in Pennsylvania \\u2026 \\n\\u201cWe don\\u2019t want to lose an election because you know what I\\u2019m talking about,\\u201d Trump told an overwhelmingly white crowd in Manheim, Pa., earlier this month. \\u201cBecause you know what? That\\u2019s a big, big problem, and nobody wants to talk about it. Nobody has the guts to talk about it. So go and watch these polling places .\\u201d \\nAnd of course reports are already pouring in from around the country of big problems with the voting machines. In Illinois this week, one candidate personally experienced a machine switching his votes from Republicans to Democrats\\u2026 \\nEarly voting in Illinois got off to a rocky start Monday, as votes being cast for Republican candidates were transformed into votes for Democrats. \\nRepublican state representative candidate Jim Moynihan went to vote Monday at the Schaumburg Public Library. \\n\\u201cI tried to cast a vote for myself and instead it cast the vote for my opponent,\\u201d Moynihan said. \\u201cYou could imagine my surprise as the same thing happened with a number of races when I tried to vote for a Republican and the machine registered a vote for a Democrat.\\u201d \\nIn addition, if you keep up with my work on The Economic Collapse Blog , then you already know that a number of voters down in Texas have reported that their votes were switched from Donald Trump to Hillary Clinton . \\nWell, it turns out that those voting machines appear to have a link to the Clinton Foundation \\u2026 \\nAccording to OpenSecrets, the company who provided the alleged glitching voting machines is a subsidiary of The McCarthy Group. \\nThe McCarthy group is a major donor to the Clinton Foundation \\u2013 apparently donating 200,000 dollars in 2007 \\u2013 when it was the largest owner of United States voting machines. Or perhaps the 200,000 dollars went to paying Bill Clinton for speeches? \\nEither way, it doesn\\u2019t look good. \\nAfter everything that we saw in 2012 , I am convinced that there is good reason to be concerned about the integrity of our voting machines. \\nBut Democrats don\\u2019t like poll observers, because they think that having too many poll observers will intimidate their voters\\u2026 \\n\\u201cIt\\u2019s un-American, but at the same time we have a long history of doing things like that ,\\u201d Ari Berman, author of the 2016 book \\u201c Give Us the Ballot: The Modern Struggle for Voting Rights in America ,\\u201d previously told The Christian Science Monitor. \\u201cVoting was very, very dangerous. I don\\u2019t think anyone\\u2019s suggesting that we\\u2019re at the same place today. I just think the loss of the [official poll observers] is going to be really problematic.\\u201d \\nWithout a doubt, this has been the craziest election season that we have seen in decades, and I have a feeling that it is about to get even crazier. \\nBut will the end result be the election of the most corrupt politician in the history of our country ? \\nIf that is the outcome after all that we have been through, it will be exceedingly depressing indeed. About the author: Michael Snyder is the founder and publisher of The Economic Collapse Blog and End Of The American Dream. Michael\\u2019s controversial new book about Bible prophecy entitled \\u201cThe Rapture Verdict\\u201d is available in paperback and for the Kindle on Amazon.com.* Share This Article...\",\n          \"PARIS  \\u2014   The French authorities on Thursday identified a second man who stormed a church in Normandy and killed an    priest as he celebrated Mass. The Paris prosecutor\\u2019s office identified the man as   Nabil Petitjean, 19. It was not clear how he knew the other killer, Adel Kermiche, also 19, who lived near the church, the \\u00c9glise St.  in St.    a   suburb of Rouen. Both were of Algerian ancestry. They were shot dead by the police after the assault on the church on Tuesday, which also left an    parishioner severely wounded he is in stable condition. The Islamic State released videos on Wednesday in which the two young men pledged allegiance to the terrorist group before the assault, which killed the Rev. Jacques Hamel. Mr. Petitjean was born in St.    in Lorraine in northeastern France, but grew up in    in the southeast. He attended a high school there, the Lyc\\u00e9e Marlioz, and his father lives in Montlu\\u00e7on, a town in central France, north of  . Mr. Petitjean flew to Turkey on June 10 but was stopped at the airport, before he reached the   desk, when he was seen talking with someone who was on the   list, according to a Turkish official who spoke on condition of anonymity. He left Turkey the next day, and was placed on a blacklist, as a precaution, the following week, and the French authorities were immediately notified, the official said. The Paris prosecutor\\u2019s office said on Thursday that Mr. Petitjean came to the attention of the police on June 29. On July 22  \\u2014   four days before the attack  \\u2014   a foreign intelligence agency sent his picture to French intelligence services, but without a name or description, the office said. Interviewed by French reporters, Mr. Petitjean\\u2019s mother, who was identified by news agencies as Yamina Boukessoula, expressed astonishment. She said he had last spoken to her early this week. She said: \\u201cHe said, \\u2018Don\\u2019t worry, get some sleep, everything is O. K.\\u2019 He had a soft voice. He sounded well. It wasn\\u2019t worrisome. He has friends, like everyone else. \\u201d The mother told reporters, \\u201cDaesh is not part of his language,\\u201d using an Arabic acronym for the Islamic State, also known as ISIS or ISIL. She said that her son had been visiting a cousin in northeastern France and that she had no idea how he had ended up in St.    the town in Normandy where the attack occurred, although he appeared to have relatives in Normandy. \\u201cI was a good mother,\\u201d she said. \\u201cI was always there for my children, maybe even too much. Malik doesn\\u2019t have psychological problems. He\\u2019s like all    with ambition, with plans. He\\u2019s smart. \\u201d Mr. Kermiche had been detained for nearly 10 months after trying, twice, to enter Syria, but he was released in March over the objections of prosecutors. He was made to wear an electronic ankle bracelet, forbidden to leave his local department of   required to report to a probation officer once a week and ordered to live in his parents\\u2019 house. He was allowed free movement from 8:30 a. m. to 12:30 p. m. on weekdays the attack on the church occurred at 9:25 a. m. The killing of the priest has elicited condemnation worldwide. On Thursday, the French Council of the Muslim Faith urged Muslims to attend Mass on Sunday morning, to \\u201cagain express solidarity with and compassion for our Christian brothers. \\u201d President Fran\\u00e7ois Hollande has again found himself confronting the specter of Islamic State terrorism  \\u2014   a rampage in Nice, on the evening of July 14, Bastille Day, which killed 84 people, followed by the attack on the church in Normandy just 12 days later  \\u2014   as the nation\\u2019s mood has increasingly turned somber. On Thursday morning, Mr. Hollande met with lawmakers to discuss the possibility of establishing a National Guard of volunteer reservists, including retired gendarmes, to help protect the nation. The plan, which he first floated in November, \\u201cis not meant to replace public forces, but to back them up and reinforce them,\\u201d Mr. Hollande said at a ceremony to open a highway in southwestern France. Mr. Hollande\\u2019s government declared a state of emergency in November. It was extended after the attack in Nice, giving the police and prosecutors expanded powers. But he has resisted calls by political rivals, including former President Nicolas Sarkozy and the leader of the   National Front, Marine Le Pen, for even more drastic constitutional and legal changes. On Thursday, Mr. Hollande reacted angrily to a comment a day earlier by Donald J. Trump, the Republican nominee for president of the United States, who, in response to the killing of the priest, said that \\u201cFrance is no longer France. \\u201d Mr. Hollande retorted: \\u201cFrance will always be France. It never gives up, because it still bears ideals, values, principles that are recognized worldwide, and it\\u2019s when you lower your standards that you are no longer what you are. That\\u2019s something that may happen to others, on the other side of the Atlantic. \\u201d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"/content/NLP dataset.xlsx\",nrows=1000)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gllEaEUhVdBP"
      },
      "source": [
        "# **Section 2: Perform Exploratory Data Analysis (EDA)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0H2k34cIU4YS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "outputId": "bda32672-6737-4952-f56e-16d40d5218bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 985 entries, 0 to 984\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   title   985 non-null    object\n",
            " 1   label   985 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 15.5+ KB\n",
            "None\n",
            "\n",
            "Missing Values:\n",
            " title    0\n",
            "label    0\n",
            "dtype: int64\n",
            "\\ Label:\n",
            " label\n",
            "0    497\n",
            "1    488\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
        "\n",
        "print(\"\\ Label:\\n\", df['label'].value_counts())\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='label', data=df, hue='label', palette='viridis', legend=False)\n",
        "plt.title(\"Price Range Distribution\")\n",
        "plt.xlabel(\"Price Range\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9rbWQAmQahj"
      },
      "source": [
        "\n",
        "# **Section 3: Perform Text Processing on Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9INErrsHQZ99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b6ea1b5-ed8d-4274-e900-53c3ae3cd292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['title', 'label'], dtype='object')\n",
            "                                               title  \\\n",
            "0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
            "1  Ever get the feeling your life circles the rou...   \n",
            "2  Why the Truth Might Get You Fired October 29, ...   \n",
            "3  Videos 15 Civilians Killed In Single US Airstr...   \n",
            "4  Print \\nAn Iranian woman has been sentenced to...   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0  house dem aide didnt even see comeys letter ja...  \n",
            "1  ever get feeling life circle roundabout rather...  \n",
            "2  truth might get fired october tension intellig...  \n",
            "3  video civilian killed single u airstrike ident...  \n",
            "4  print iranian woman sentenced six year prison ...  \n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# ✅ Download required NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# ✅ Define stop words and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# ✅ Function to clean text\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):  # Ensure text is valid\n",
        "        return \"\"  # Return empty string for NaN values\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I | re.A).lower()\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    words = [lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# ✅ Corrected file path\n",
        "file_path = \"/content/NLP dataset.xlsx\"\n",
        "\n",
        "# ✅ Load dataset with nrows=1000 correctly placed\n",
        "df = pd.read_excel(file_path, nrows=1000)\n",
        "\n",
        "# ✅ Check actual column names\n",
        "print(df.columns)\n",
        "\n",
        "# ✅ Fix column name if needed\n",
        "if 'title' in df.columns:\n",
        "    df['cleaned_text'] = df['title'].apply(clean_text)\n",
        "else:\n",
        "    print(\"❌ Error: 'title' column not found. Check dataset columns.\")\n",
        "\n",
        "# ✅ Display output\n",
        "print(df[['title', 'cleaned_text']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qU_Jl8zQZfN"
      },
      "source": [
        "# **Section 4: Generate NLP-Based Features**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"  # Ensure text is always a string\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I | re.A)  # Remove non-alphabetic characters\n",
        "    text = text.lower().strip()  # Convert to lowercase and strip spaces\n",
        "    return text\n",
        "df['cleaned_text'] = df['title'].apply(clean_text)\n",
        "\n",
        "def generate_nlp_features(df):\n",
        "\n",
        "    df['char_count'] = df['cleaned_text'].apply(len)\n",
        "    df['word_count'] = df['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "    df['avg_word_length'] = df['cleaned_text'].apply(lambda x: np.mean([len(word) for word in x.split()]))\n",
        "    df['stopword_count'] = df['cleaned_text'].apply(lambda x: len([word for word in x.split() if word in stop_words]))\n",
        "    df['unique_word_count'] = df['cleaned_text'].apply(lambda x: len(set(x.split())))\n",
        "    df['lexical_diversity'] = df['unique_word_count'] / df['word_count']\n",
        "    df['most_common_word'] = df['cleaned_text'].apply(lambda x: Counter(x.split()).most_common(1)[0][0] if x else '')\n",
        "    df['sentence_count'] = df['title'].apply(lambda x: len([s for s in re.split(r'[.!?]', str(x)) if s.strip()]))\n",
        "    df['avg_sentence_length'] = df['word_count'] / df['sentence_count']\n",
        "    return df\n",
        "df = generate_nlp_features(df)\n",
        "df[['char_count', 'word_count', 'avg_word_length', 'stopword_count', 'unique_word_count', 'lexical_diversity', 'most_common_word', 'sentence_count', 'avg_sentence_length']].head()\n",
        "\n"
      ],
      "metadata": {
        "id": "SkggYpuXkRaD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "229e3f76-bfb4-47a1-807d-1349cca70e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   char_count  word_count  avg_word_length  stopword_count  unique_word_count  \\\n",
              "0        4787         809         4.892460             369                358   \n",
              "1        4010         693         4.738817             324                361   \n",
              "2        7438        1238         4.968498             554                553   \n",
              "3        3144         541         4.757856             241                236   \n",
              "4         906         148         5.060811              61                 93   \n",
              "\n",
              "   lexical_diversity most_common_word  sentence_count  avg_sentence_length  \n",
              "0           0.442522              the              38            21.289474  \n",
              "1           0.520924              the              34            20.382353  \n",
              "2           0.446688              the              73            16.958904  \n",
              "3           0.436229              the              29            18.655172  \n",
              "4           0.628378              the               5            29.600000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da8e169c-7f01-42a9-8f88-3eef62964988\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>stopword_count</th>\n",
              "      <th>unique_word_count</th>\n",
              "      <th>lexical_diversity</th>\n",
              "      <th>most_common_word</th>\n",
              "      <th>sentence_count</th>\n",
              "      <th>avg_sentence_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4787</td>\n",
              "      <td>809</td>\n",
              "      <td>4.892460</td>\n",
              "      <td>369</td>\n",
              "      <td>358</td>\n",
              "      <td>0.442522</td>\n",
              "      <td>the</td>\n",
              "      <td>38</td>\n",
              "      <td>21.289474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4010</td>\n",
              "      <td>693</td>\n",
              "      <td>4.738817</td>\n",
              "      <td>324</td>\n",
              "      <td>361</td>\n",
              "      <td>0.520924</td>\n",
              "      <td>the</td>\n",
              "      <td>34</td>\n",
              "      <td>20.382353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7438</td>\n",
              "      <td>1238</td>\n",
              "      <td>4.968498</td>\n",
              "      <td>554</td>\n",
              "      <td>553</td>\n",
              "      <td>0.446688</td>\n",
              "      <td>the</td>\n",
              "      <td>73</td>\n",
              "      <td>16.958904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3144</td>\n",
              "      <td>541</td>\n",
              "      <td>4.757856</td>\n",
              "      <td>241</td>\n",
              "      <td>236</td>\n",
              "      <td>0.436229</td>\n",
              "      <td>the</td>\n",
              "      <td>29</td>\n",
              "      <td>18.655172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>906</td>\n",
              "      <td>148</td>\n",
              "      <td>5.060811</td>\n",
              "      <td>61</td>\n",
              "      <td>93</td>\n",
              "      <td>0.628378</td>\n",
              "      <td>the</td>\n",
              "      <td>5</td>\n",
              "      <td>29.600000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da8e169c-7f01-42a9-8f88-3eef62964988')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-da8e169c-7f01-42a9-8f88-3eef62964988 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-da8e169c-7f01-42a9-8f88-3eef62964988');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-26601c90-a2e5-4d6c-a368-23e08fffb235\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26601c90-a2e5-4d6c-a368-23e08fffb235')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-26601c90-a2e5-4d6c-a368-23e08fffb235 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[['char_count', 'word_count', 'avg_word_length', 'stopword_count', 'unique_word_count', 'lexical_diversity', 'most_common_word', 'sentence_count', 'avg_sentence_length']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"char_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2383,\n        \"min\": 906,\n        \"max\": 7438,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4010,\n          906,\n          7438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 396,\n        \"min\": 148,\n        \"max\": 1238,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          693,\n          148,\n          1238\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13735312024310561,\n        \"min\": 4.738816738816739,\n        \"max\": 5.0608108108108105,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.738816738816739,\n          5.0608108108108105,\n          4.968497576736672\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stopword_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 180,\n        \"min\": 61,\n        \"max\": 554,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          324,\n          61,\n          554\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique_word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 170,\n        \"min\": 93,\n        \"max\": 553,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          361,\n          93,\n          553\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lexical_diversity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08216419866194365,\n        \"min\": 0.43622920517560076,\n        \"max\": 0.6283783783783784,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5209235209235209,\n          0.6283783783783784,\n          0.4466882067851373\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"most_common_word\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"the\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24,\n        \"min\": 5,\n        \"max\": 73,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_sentence_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.887295498799656,\n        \"min\": 16.958904109589042,\n        \"max\": 29.6,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          20.38235294117647\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzsZObdRa5bO"
      },
      "source": [
        "# **Section 5: Generate Bag of Words, TFIDF, and FastText Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6jlre6g_c73g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd23c1f9-6b63-4f49-90c1-1401792e1fc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (1.26.4)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4313473 sha256=fc31f40d26c73811a074577f9ec71d9b883e29bb9cb8959d084b40dd998002a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tupWo0ITejgZ",
        "outputId": "63bdfdb6-80de-4f34-a61c-12b75e8b6c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-16 22:24:42--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.171.22.13, 3.171.22.33, 3.171.22.68, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.171.22.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.en.300.bin.gz’\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G  47.6MB/s    in 69s     \n",
            "\n",
            "2025-03-16 22:25:52 (62.0 MB/s) - ‘cc.en.300.bin.gz’ saved [4503593528/4503593528]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!rm -f cc.en.300.bin.gz\n",
        "!wget -O cc.en.300.bin.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "!gunzip -f cc.en.300.bin.gz\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGDNb1mKg3J_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "287876c9-f59b-4daa-cfb9-193ff6a84daf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW Shape: (985, 5000)\n",
            "TFIDF Shape: (985, 5000)\n",
            "FastText Embeddings Shape: (985, 300)\n",
            "Sample BoW Features: [[0 0 0 ... 0 0 0]]\n",
            "Sample TFIDF Features: [[0. 0. 0. ... 0. 0. 0.]]\n",
            "Sample FastText Embedding: [-1.67314801e-02 -1.94957275e-02 -1.21264136e-03  4.23143581e-02\n",
            " -6.35084361e-02 -4.24843095e-03  1.15706818e-02 -8.61783046e-03\n",
            " -8.50008242e-03 -2.87558534e-03 -1.78560540e-02  8.19165073e-03\n",
            "  8.49803165e-03  2.87050311e-03 -2.23310757e-02  2.33430099e-02\n",
            "  8.84812977e-03  1.76828413e-03 -3.37990113e-02  2.87178513e-02\n",
            "  1.50719090e-04  1.96195357e-02  2.66693346e-03 -2.32726075e-02\n",
            " -2.86462847e-02 -3.56059261e-02 -8.35868157e-03  1.52013432e-02\n",
            " -2.00837944e-02  9.55454037e-02 -4.88196546e-03 -1.69568043e-02\n",
            " -7.75846536e-04 -3.99869494e-02 -6.30993815e-03 -4.05558292e-03\n",
            "  2.72140768e-03  3.23323347e-02  5.98852988e-03  2.07893644e-03\n",
            " -2.84329103e-03  8.65296088e-03 -1.82930455e-02  2.30466202e-02\n",
            "  1.06625613e-02  1.06624085e-02  3.77986988e-04  2.39166897e-02\n",
            " -1.58243161e-02  1.00061875e-02  4.97306976e-03  4.74671694e-03\n",
            " -7.03967502e-03 -2.81944536e-02 -1.04049137e-02 -1.25097549e-02\n",
            " -7.82650895e-03  1.32242931e-04 -5.01611382e-02 -1.80563536e-02\n",
            "  5.36534656e-03 -3.53058754e-03 -7.17235450e-03 -6.56674653e-02\n",
            " -1.27807558e-02  1.97829329e-03 -1.90179460e-02 -8.52100272e-03\n",
            " -4.57162457e-03 -1.73393227e-02 -1.63223688e-02  8.39471072e-03\n",
            "  2.36178115e-02 -1.22579485e-02  4.71431250e-03 -2.09868215e-02\n",
            "  1.73978880e-02  1.35607440e-02  2.40211859e-02 -7.50194583e-03\n",
            " -4.00942424e-03 -1.30743338e-02 -2.09108014e-02  2.46697273e-02\n",
            "  1.32665131e-02  1.84039108e-03  3.51938941e-02 -1.41667444e-02\n",
            "  2.37157773e-02 -2.74340506e-03 -1.49037549e-02 -9.91080608e-03\n",
            "  6.16733432e-02  1.95104699e-03  1.07413810e-02  2.16850247e-02\n",
            " -2.05412898e-02  6.27111318e-03 -1.94283035e-02  1.31036676e-02\n",
            "  8.39746930e-03  1.95659045e-02  2.21885759e-02 -4.71364111e-02\n",
            "  8.94667115e-03  7.69782765e-03  5.13559440e-03  1.00244982e-02\n",
            "  2.90631992e-03 -1.49514060e-03  1.34997535e-02  3.82509269e-03\n",
            " -5.88931143e-03  5.16939946e-02  2.82854959e-03 -1.61317084e-02\n",
            " -2.21632570e-02  8.00017826e-03 -1.02908202e-02 -5.12868352e-03\n",
            "  7.26222759e-03  4.01285896e-03  4.09952831e-03  1.79800554e-03\n",
            "  1.27934804e-02  2.51671616e-02 -6.95306575e-04 -1.10100452e-02\n",
            " -2.03606114e-02  4.47725207e-02 -1.68582313e-02 -1.78383198e-02\n",
            "  1.96135975e-02  3.30606215e-02 -6.82180631e-04 -1.58342104e-02\n",
            " -5.13729490e-02 -4.23358846e-03  1.50895631e-02  6.40603155e-03\n",
            " -3.12063694e-02 -3.49576981e-03  4.34281072e-03  1.12650525e-02\n",
            "  1.21522145e-02  1.70525573e-02 -3.16277564e-01  1.28749842e-02\n",
            " -1.09568024e-02 -9.77633893e-03 -1.00340873e-01  1.06548220e-02\n",
            "  4.02588844e-02  2.00401545e-02 -4.10293462e-03 -2.86022597e-03\n",
            "  1.14959255e-01  2.90119927e-03  4.40886384e-03  2.29995102e-02\n",
            " -1.38556678e-03 -1.60897290e-03  3.62827256e-02 -3.12831327e-02\n",
            "  9.52792820e-03 -9.02959425e-03  1.98914531e-05 -1.39283510e-02\n",
            "  2.84848642e-03  5.98960975e-03 -1.12081710e-02 -1.15592731e-04\n",
            "  2.33542528e-02 -1.36045152e-02 -6.10162225e-03 -5.79612504e-04\n",
            " -2.75089312e-03 -1.21912640e-02  3.86062369e-04 -1.28902122e-02\n",
            "  4.94242227e-03  7.16881379e-02 -1.07237874e-02  1.43381476e-04\n",
            "  6.67358283e-04  5.60037494e-02 -1.09011419e-02 -3.62465717e-02\n",
            "  5.74585889e-03 -2.76209740e-03 -1.83069874e-02  2.22713742e-02\n",
            " -9.50096175e-03 -2.51993295e-02  7.19074951e-03  1.37075828e-02\n",
            " -5.38311806e-03 -1.08375913e-02  3.09223644e-02  3.42680253e-02\n",
            " -3.56131792e-02  1.69446811e-01  2.68809032e-02 -2.46952381e-02\n",
            "  1.26175797e-02  3.57224955e-04 -1.83462277e-02 -1.19591616e-02\n",
            "  1.52643290e-04  1.34997547e-03 -1.23263765e-02 -5.71809197e-03\n",
            " -3.87562551e-02  7.54246162e-03  4.66814963e-03 -1.43899340e-02\n",
            "  1.73372515e-02  1.32043016e-04  1.72027126e-02  1.03389658e-02\n",
            "  1.67168565e-02  1.35530876e-02  1.88354834e-03  2.81898435e-02\n",
            "  2.53556471e-04 -1.22544402e-02 -6.21802732e-03  3.23703559e-03\n",
            " -9.57750526e-05 -4.08712961e-03 -1.87908188e-02  3.65168625e-03\n",
            " -2.09416617e-02  1.50478934e-03  1.68840960e-02 -2.33778059e-02\n",
            "  1.85103677e-02  4.65645781e-03 -1.29165044e-02  1.93278827e-02\n",
            "  3.44344159e-03  5.25493398e-02 -1.44658852e-02 -9.70747173e-02\n",
            "  4.01677489e-01 -2.22703815e-02 -5.42526040e-03  2.15153806e-02\n",
            " -1.04363998e-02 -4.80058277e-03  1.70324780e-02  1.63721237e-02\n",
            " -3.21076531e-03  8.73161200e-03  1.19416276e-02  3.50281713e-03\n",
            " -5.69825657e-02 -1.15944492e-02 -4.80919285e-03  1.98602993e-02\n",
            " -1.16511500e-02  2.87022106e-02 -2.55357791e-02  1.67311227e-03\n",
            " -1.25512853e-02  3.21938121e-03  6.20586704e-03  8.54017620e-04\n",
            "  1.71617307e-02 -4.40283455e-02 -2.02752370e-02 -3.17704082e-02\n",
            " -2.45781578e-02 -1.56080099e-02  1.65150277e-02 -1.60992891e-02\n",
            " -1.42272804e-02 -2.66352352e-02 -9.65579599e-03  1.27581332e-03\n",
            " -2.52506486e-03  5.58073923e-04 -1.57159179e-01 -3.09974663e-02\n",
            "  3.54853459e-03 -7.49904430e-03  1.25917308e-02 -2.85787992e-02\n",
            " -3.05420123e-02  4.84016957e-03  3.78310680e-02 -4.49763640e-04\n",
            " -1.09469034e-01  1.38741648e-02 -1.40137905e-02  1.16879940e-02\n",
            " -1.03477121e-03  1.34720996e-01 -1.67157706e-02  5.75792044e-03]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import fasttext\n",
        "\n",
        "# Bag of Words (BoW)\n",
        "bow_vectorizer = CountVectorizer(max_features=5000)\n",
        "X_bow = bow_vectorizer.fit_transform(df['cleaned_text'])\n",
        "print(f\"BoW Shape: {X_bow.shape}\")\n",
        "\n",
        "# TFIDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['cleaned_text'])\n",
        "print(f\"TFIDF Shape: {X_tfidf.shape}\")\n",
        "\n",
        "# Load FastText model\n",
        "ft_model = fasttext.load_model('cc.en.300.bin')\n",
        "\n",
        "def get_fasttext_embeddings(text):\n",
        "    words = text.split()\n",
        "    if not words:\n",
        "        return np.zeros(300)\n",
        "    word_vectors = [ft_model.get_word_vector(word) for word in words]\n",
        "    return np.mean(word_vectors, axis=0)\n",
        "\n",
        "\n",
        "df['fasttext_embeddings'] = df['cleaned_text'].apply(get_fasttext_embeddings)\n",
        "\n",
        "\n",
        "fasttext_embeddings = np.vstack(df['fasttext_embeddings'].values)\n",
        "print(f\"FastText Embeddings Shape: {fasttext_embeddings.shape}\")\n",
        "\n",
        "\n",
        "print(\"Sample BoW Features:\", X_bow[0].toarray())  # First row of BoW\n",
        "print(\"Sample TFIDF Features:\", X_tfidf[0].toarray())  # First row of TFIDF\n",
        "print(\"Sample FastText Embedding:\", fasttext_embeddings[0])  # First row of FastText\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGJNMvsCh3e_"
      },
      "source": [
        "\n",
        "# **Section 6: Train All Supervised Models on NLP-Based Features**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Available columns:\", df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "Noscxl60iRmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b97e8d4-449e-4e77-e11a-31cd1c5a3a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available columns: ['title', 'label', 'cleaned_text', 'char_count', 'word_count', 'avg_word_length', 'stopword_count', 'unique_word_count', 'lexical_diversity', 'most_common_word', 'sentence_count', 'avg_sentence_length', 'fasttext_embeddings']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y90qKokrh88z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81a467b-9d19-41c3-d855-5ea49a43f82b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Random Forest ---\n",
            "Accuracy: 0.6700507614213198\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.69      0.69       107\n",
            "           1       0.64      0.64      0.64        90\n",
            "\n",
            "    accuracy                           0.67       197\n",
            "   macro avg       0.67      0.67      0.67       197\n",
            "weighted avg       0.67      0.67      0.67       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Logistic Regression ---\n",
            "Accuracy: 0.6852791878172588\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.55      0.66       107\n",
            "           1       0.61      0.84      0.71        90\n",
            "\n",
            "    accuracy                           0.69       197\n",
            "   macro avg       0.71      0.70      0.68       197\n",
            "weighted avg       0.72      0.69      0.68       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- SGD Classifier ---\n",
            "Accuracy: 0.583756345177665\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      1.00      0.72       107\n",
            "           1       1.00      0.09      0.16        90\n",
            "\n",
            "    accuracy                           0.58       197\n",
            "   macro avg       0.78      0.54      0.44       197\n",
            "weighted avg       0.76      0.58      0.47       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- SVM ---\n",
            "Accuracy: 0.6091370558375635\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.59      0.62       107\n",
            "           1       0.56      0.63      0.60        90\n",
            "\n",
            "    accuracy                           0.61       197\n",
            "   macro avg       0.61      0.61      0.61       197\n",
            "weighted avg       0.61      0.61      0.61       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- KNN ---\n",
            "Accuracy: 0.5786802030456852\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.62      0.61       107\n",
            "           1       0.54      0.53      0.54        90\n",
            "\n",
            "    accuracy                           0.58       197\n",
            "   macro avg       0.58      0.58      0.58       197\n",
            "weighted avg       0.58      0.58      0.58       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Multinomial NB ---\n",
            "Accuracy: 0.6649746192893401\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.53      0.63       107\n",
            "           1       0.60      0.82      0.69        90\n",
            "\n",
            "    accuracy                           0.66       197\n",
            "   macro avg       0.69      0.68      0.66       197\n",
            "weighted avg       0.70      0.66      0.66       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Gaussian NB ---\n",
            "Accuracy: 0.700507614213198\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.79      0.74       107\n",
            "           1       0.70      0.60      0.65        90\n",
            "\n",
            "    accuracy                           0.70       197\n",
            "   macro avg       0.70      0.69      0.69       197\n",
            "weighted avg       0.70      0.70      0.70       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Bernoulli NB ---\n",
            "Accuracy: 0.5634517766497462\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      1.00      0.71       107\n",
            "           1       1.00      0.04      0.09        90\n",
            "\n",
            "    accuracy                           0.56       197\n",
            "   macro avg       0.78      0.52      0.40       197\n",
            "weighted avg       0.76      0.56      0.43       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Decision Tree ---\n",
            "Accuracy: 0.649746192893401\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.68      0.68       107\n",
            "           1       0.62      0.61      0.61        90\n",
            "\n",
            "    accuracy                           0.65       197\n",
            "   macro avg       0.65      0.65      0.65       197\n",
            "weighted avg       0.65      0.65      0.65       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Final Comparison Table:\n",
            "\n",
            "                 Model  Accuracy\n",
            "6          Gaussian NB  0.700508\n",
            "1  Logistic Regression  0.685279\n",
            "0        Random Forest  0.670051\n",
            "5       Multinomial NB  0.664975\n",
            "8        Decision Tree  0.649746\n",
            "3                  SVM  0.609137\n",
            "2       SGD Classifier  0.583756\n",
            "4                  KNN  0.578680\n",
            "7         Bernoulli NB  0.563452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import fasttext\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "X = df[['char_count', 'word_count', 'avg_word_length', 'stopword_count', 'unique_word_count', 'lexical_diversity', 'sentence_count', 'avg_sentence_length']]\n",
        "y = df['label']\n",
        "X = X.fillna(0)  # Replace missing feature values with 0\n",
        "y = y.fillna(y.mode()[0])  # Replace missing labels with most frequent label\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'SGD Classifier': SGDClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Multinomial NB': MultinomialNB(),\n",
        "    'Gaussian NB': GaussianNB(),\n",
        "    'Bernoulli NB': BernoulliNB(),\n",
        "    'Decision Tree': DecisionTreeClassifier()\n",
        "}\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name == 'Gaussian NB':\n",
        "        model.fit(X_train.to_numpy(), y_train)\n",
        "        y_pred = model.predict(X_test.to_numpy())\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'--- {name} ---')\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print('\\n' + '-'*50 + '\\n')\n",
        "\n",
        "\n",
        "    results.append([name, accuracy])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy'])\n",
        "print(\"\\nFinal Comparison Table:\\n\")\n",
        "print(results_df.sort_values(by=\"Accuracy\", ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xYpv5hJkXTW"
      },
      "source": [
        "# **Sections 7-9: Train Models on BoW, TFIDF, and FastText Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiXQbbD3i1IQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2109c56d-715b-4bb4-87a3-27361a244312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training models on Bag of Words (BoW) features...\n",
            "\n",
            "--- Random Forest (BoW) ---\n",
            "Accuracy: 0.8375634517766497\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       107\n",
            "           1       0.82      0.82      0.82        90\n",
            "\n",
            "    accuracy                           0.84       197\n",
            "   macro avg       0.84      0.84      0.84       197\n",
            "weighted avg       0.84      0.84      0.84       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Logistic Regression (BoW) ---\n",
            "Accuracy: 0.8730964467005076\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88       107\n",
            "           1       0.85      0.88      0.86        90\n",
            "\n",
            "    accuracy                           0.87       197\n",
            "   macro avg       0.87      0.87      0.87       197\n",
            "weighted avg       0.87      0.87      0.87       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SGD Classifier (BoW) ---\n",
            "Accuracy: 0.868020304568528\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88       107\n",
            "           1       0.86      0.86      0.86        90\n",
            "\n",
            "    accuracy                           0.87       197\n",
            "   macro avg       0.87      0.87      0.87       197\n",
            "weighted avg       0.87      0.87      0.87       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- SVM (BoW) ---\n",
            "Accuracy: 0.7106598984771574\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.54      0.67       107\n",
            "           1       0.63      0.91      0.74        90\n",
            "\n",
            "    accuracy                           0.71       197\n",
            "   macro avg       0.75      0.73      0.71       197\n",
            "weighted avg       0.76      0.71      0.70       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- KNN (BoW) ---\n",
            "Accuracy: 0.7461928934010152\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.67      0.74       107\n",
            "           1       0.68      0.83      0.75        90\n",
            "\n",
            "    accuracy                           0.75       197\n",
            "   macro avg       0.75      0.75      0.75       197\n",
            "weighted avg       0.76      0.75      0.75       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Multinomial NB (BoW) ---\n",
            "Accuracy: 0.8375634517766497\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.83      0.85       107\n",
            "           1       0.81      0.84      0.83        90\n",
            "\n",
            "    accuracy                           0.84       197\n",
            "   macro avg       0.84      0.84      0.84       197\n",
            "weighted avg       0.84      0.84      0.84       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Gaussian NB (BoW) ---\n",
            "Accuracy: 0.8223350253807107\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.84       107\n",
            "           1       0.80      0.81      0.81        90\n",
            "\n",
            "    accuracy                           0.82       197\n",
            "   macro avg       0.82      0.82      0.82       197\n",
            "weighted avg       0.82      0.82      0.82       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Bernoulli NB (BoW) ---\n",
            "Accuracy: 0.7258883248730964\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.64      0.72       107\n",
            "           1       0.66      0.83      0.74        90\n",
            "\n",
            "    accuracy                           0.73       197\n",
            "   macro avg       0.74      0.73      0.73       197\n",
            "weighted avg       0.75      0.73      0.72       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Decision Tree (BoW) ---\n",
            "Accuracy: 0.7360406091370558\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.73      0.75       107\n",
            "           1       0.70      0.74      0.72        90\n",
            "\n",
            "    accuracy                           0.74       197\n",
            "   macro avg       0.74      0.74      0.74       197\n",
            "weighted avg       0.74      0.74      0.74       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Training models on TFIDF features...\n",
            "\n",
            "--- Random Forest (TFIDF) ---\n",
            "Accuracy: 0.8781725888324873\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.87      0.89       107\n",
            "           1       0.85      0.89      0.87        90\n",
            "\n",
            "    accuracy                           0.88       197\n",
            "   macro avg       0.88      0.88      0.88       197\n",
            "weighted avg       0.88      0.88      0.88       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Logistic Regression (TFIDF) ---\n",
            "Accuracy: 0.8071065989847716\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.75      0.81       107\n",
            "           1       0.75      0.88      0.81        90\n",
            "\n",
            "    accuracy                           0.81       197\n",
            "   macro avg       0.81      0.81      0.81       197\n",
            "weighted avg       0.82      0.81      0.81       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- SGD Classifier (TFIDF) ---\n",
            "Accuracy: 0.8629441624365483\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.87       107\n",
            "           1       0.85      0.86      0.85        90\n",
            "\n",
            "    accuracy                           0.86       197\n",
            "   macro avg       0.86      0.86      0.86       197\n",
            "weighted avg       0.86      0.86      0.86       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- SVM (TFIDF) ---\n",
            "Accuracy: 0.817258883248731\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.77      0.82       107\n",
            "           1       0.76      0.88      0.81        90\n",
            "\n",
            "    accuracy                           0.82       197\n",
            "   macro avg       0.82      0.82      0.82       197\n",
            "weighted avg       0.83      0.82      0.82       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- KNN (TFIDF) ---\n",
            "Accuracy: 0.6395939086294417\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.36      0.52       107\n",
            "           1       0.56      0.97      0.71        90\n",
            "\n",
            "    accuracy                           0.64       197\n",
            "   macro avg       0.74      0.67      0.62       197\n",
            "weighted avg       0.76      0.64      0.61       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Multinomial NB (TFIDF) ---\n",
            "Accuracy: 0.8274111675126904\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85       107\n",
            "           1       0.86      0.74      0.80        90\n",
            "\n",
            "    accuracy                           0.83       197\n",
            "   macro avg       0.83      0.82      0.82       197\n",
            "weighted avg       0.83      0.83      0.83       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Gaussian NB (TFIDF) ---\n",
            "Accuracy: 0.7766497461928934\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.86      0.81       107\n",
            "           1       0.80      0.68      0.73        90\n",
            "\n",
            "    accuracy                           0.78       197\n",
            "   macro avg       0.78      0.77      0.77       197\n",
            "weighted avg       0.78      0.78      0.77       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Bernoulli NB (TFIDF) ---\n",
            "Accuracy: 0.7258883248730964\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.64      0.72       107\n",
            "           1       0.66      0.83      0.74        90\n",
            "\n",
            "    accuracy                           0.73       197\n",
            "   macro avg       0.74      0.73      0.73       197\n",
            "weighted avg       0.75      0.73      0.72       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Decision Tree (TFIDF) ---\n",
            "Accuracy: 0.7309644670050761\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.73      0.75       107\n",
            "           1       0.69      0.73      0.71        90\n",
            "\n",
            "    accuracy                           0.73       197\n",
            "   macro avg       0.73      0.73      0.73       197\n",
            "weighted avg       0.73      0.73      0.73       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Training models on FastText features...\n",
            "\n",
            "--- Random Forest (FastText) ---\n",
            "Accuracy: 0.7868020304568528\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.75      0.79       107\n",
            "           1       0.74      0.83      0.78        90\n",
            "\n",
            "    accuracy                           0.79       197\n",
            "   macro avg       0.79      0.79      0.79       197\n",
            "weighted avg       0.79      0.79      0.79       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Logistic Regression (FastText) ---\n",
            "Accuracy: 0.7157360406091371\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.67      0.72       107\n",
            "           1       0.66      0.77      0.71        90\n",
            "\n",
            "    accuracy                           0.72       197\n",
            "   macro avg       0.72      0.72      0.72       197\n",
            "weighted avg       0.72      0.72      0.72       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- SGD Classifier (FastText) ---\n",
            "Accuracy: 0.7817258883248731\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.70      0.78       107\n",
            "           1       0.71      0.88      0.79        90\n",
            "\n",
            "    accuracy                           0.78       197\n",
            "   macro avg       0.79      0.79      0.78       197\n",
            "weighted avg       0.80      0.78      0.78       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- SVM (FastText) ---\n",
            "Accuracy: 0.7614213197969543\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.71      0.76       107\n",
            "           1       0.70      0.82      0.76        90\n",
            "\n",
            "    accuracy                           0.76       197\n",
            "   macro avg       0.77      0.77      0.76       197\n",
            "weighted avg       0.77      0.76      0.76       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- KNN (FastText) ---\n",
            "Accuracy: 0.6903553299492385\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.67      0.70       107\n",
            "           1       0.65      0.71      0.68        90\n",
            "\n",
            "    accuracy                           0.69       197\n",
            "   macro avg       0.69      0.69      0.69       197\n",
            "weighted avg       0.69      0.69      0.69       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Gaussian NB (FastText) ---\n",
            "Accuracy: 0.6395939086294417\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.93      0.74       107\n",
            "           1       0.79      0.29      0.42        90\n",
            "\n",
            "    accuracy                           0.64       197\n",
            "   macro avg       0.70      0.61      0.58       197\n",
            "weighted avg       0.69      0.64      0.59       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Bernoulli NB (FastText) ---\n",
            "Accuracy: 0.6903553299492385\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.74      0.72       107\n",
            "           1       0.67      0.63      0.65        90\n",
            "\n",
            "    accuracy                           0.69       197\n",
            "   macro avg       0.69      0.69      0.69       197\n",
            "weighted avg       0.69      0.69      0.69       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Decision Tree (FastText) ---\n",
            "Accuracy: 0.7106598984771574\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.70      0.72       107\n",
            "           1       0.67      0.72      0.70        90\n",
            "\n",
            "    accuracy                           0.71       197\n",
            "   macro avg       0.71      0.71      0.71       197\n",
            "weighted avg       0.71      0.71      0.71       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Final Comparison Table:\n",
            "\n",
            "                  Model Feature Type  Accuracy\n",
            "1   Logistic Regression          BoW  0.873096\n",
            "2        SGD Classifier          BoW  0.868020\n",
            "0         Random Forest          BoW  0.837563\n",
            "5        Multinomial NB          BoW  0.837563\n",
            "6           Gaussian NB          BoW  0.822335\n",
            "4                   KNN          BoW  0.746193\n",
            "8         Decision Tree          BoW  0.736041\n",
            "7          Bernoulli NB          BoW  0.725888\n",
            "3                   SVM          BoW  0.710660\n",
            "18        Random Forest     FastText  0.786802\n",
            "20       SGD Classifier     FastText  0.781726\n",
            "21                  SVM     FastText  0.761421\n",
            "19  Logistic Regression     FastText  0.715736\n",
            "25        Decision Tree     FastText  0.710660\n",
            "22                  KNN     FastText  0.690355\n",
            "24         Bernoulli NB     FastText  0.690355\n",
            "23          Gaussian NB     FastText  0.639594\n",
            "9         Random Forest        TFIDF  0.878173\n",
            "11       SGD Classifier        TFIDF  0.862944\n",
            "14       Multinomial NB        TFIDF  0.827411\n",
            "12                  SVM        TFIDF  0.817259\n",
            "10  Logistic Regression        TFIDF  0.807107\n",
            "15          Gaussian NB        TFIDF  0.776650\n",
            "17        Decision Tree        TFIDF  0.730964\n",
            "16         Bernoulli NB        TFIDF  0.725888\n",
            "13                  KNN        TFIDF  0.639594\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import fasttext\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'SGD Classifier': SGDClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Multinomial NB': MultinomialNB(),\n",
        "    'Gaussian NB': GaussianNB(),\n",
        "    'Bernoulli NB': BernoulliNB(),\n",
        "    'Decision Tree': DecisionTreeClassifier()\n",
        "}\n",
        "results = []\n",
        "\n",
        "# Train models on Bag of Words (BoW)\n",
        "print(\"\\nTraining models on Bag of Words (BoW) features...\\n\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
        "for name, model in models.items():\n",
        "    if name == 'Gaussian NB':\n",
        "        model.fit(X_train.toarray(), y_train)\n",
        "        y_pred = model.predict(X_test.toarray())\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'--- {name} (BoW) ---')\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print('\\n' + '-'*50 + '\\n')\n",
        "\n",
        "    results.append([name, 'BoW', accuracy])\n",
        "\n",
        "# Train models on TFIDF\n",
        "print(\"\\nTraining models on TFIDF features...\\n\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "for name, model in models.items():\n",
        "    if name == 'Gaussian NB':\n",
        "        model.fit(X_train.toarray(), y_train)\n",
        "        y_pred = model.predict(X_test.toarray())\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'--- {name} (TFIDF) ---')\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print('\\n' + '-'*50 + '\\n')\n",
        "\n",
        "    results.append([name, 'TFIDF', accuracy])\n",
        "\n",
        "# Train models on FastText (Skipping MultinomialNB)\n",
        "print(\"\\nTraining models on FastText features...\\n\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.vstack(df['fasttext_embeddings']), y, test_size=0.2, random_state=42)\n",
        "for name, model in models.items():\n",
        "    if name != 'Multinomial NB':  # Skip MultinomialNB for FastText\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f'--- {name} (FastText) ---')\n",
        "        print(f'Accuracy: {accuracy}')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "        print('\\n' + '-'*50 + '\\n')\n",
        "\n",
        "        results.append([name, 'FastText', accuracy])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=['Model', 'Feature Type', 'Accuracy'])\n",
        "print(\"\\nFinal Comparison Table:\\n\")\n",
        "print(results_df.sort_values(by=[\"Feature Type\", \"Accuracy\"], ascending=[True, False]))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fit5dXNFn1sK"
      },
      "source": [
        "\n",
        "# **Section 10: Train Models on All Combined Features with TFIDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5UNUyUvvusT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6606ee14-921e-41e4-abaf-e6ab40584bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Random Forest (NLP + TFIDF) ---\n",
            "Accuracy: 0.8730964467005076\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88       107\n",
            "           1       0.87      0.86      0.86        90\n",
            "\n",
            "    accuracy                           0.87       197\n",
            "   macro avg       0.87      0.87      0.87       197\n",
            "weighted avg       0.87      0.87      0.87       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Logistic Regression (NLP + TFIDF) ---\n",
            "Accuracy: 0.6852791878172588\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.54      0.65       107\n",
            "           1       0.61      0.86      0.71        90\n",
            "\n",
            "    accuracy                           0.69       197\n",
            "   macro avg       0.71      0.70      0.68       197\n",
            "weighted avg       0.72      0.69      0.68       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SGD Classifier (NLP + TFIDF) ---\n",
            "Accuracy: 0.6040609137055838\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      1.00      0.73       107\n",
            "           1       1.00      0.13      0.24        90\n",
            "\n",
            "    accuracy                           0.60       197\n",
            "   macro avg       0.79      0.57      0.48       197\n",
            "weighted avg       0.77      0.60      0.51       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- SVM (NLP + TFIDF) ---\n",
            "Accuracy: 0.6091370558375635\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.59      0.62       107\n",
            "           1       0.56      0.63      0.60        90\n",
            "\n",
            "    accuracy                           0.61       197\n",
            "   macro avg       0.61      0.61      0.61       197\n",
            "weighted avg       0.61      0.61      0.61       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- KNN (NLP + TFIDF) ---\n",
            "Accuracy: 0.5786802030456852\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.62      0.61       107\n",
            "           1       0.54      0.53      0.54        90\n",
            "\n",
            "    accuracy                           0.58       197\n",
            "   macro avg       0.58      0.58      0.58       197\n",
            "weighted avg       0.58      0.58      0.58       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Multinomial NB (NLP + TFIDF) ---\n",
            "Accuracy: 0.6598984771573604\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.58      0.65       107\n",
            "           1       0.60      0.76      0.67        90\n",
            "\n",
            "    accuracy                           0.66       197\n",
            "   macro avg       0.67      0.67      0.66       197\n",
            "weighted avg       0.68      0.66      0.66       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Gaussian NB (NLP + TFIDF) ---\n",
            "Accuracy: 0.7055837563451777\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.90      0.77       107\n",
            "           1       0.80      0.48      0.60        90\n",
            "\n",
            "    accuracy                           0.71       197\n",
            "   macro avg       0.73      0.69      0.68       197\n",
            "weighted avg       0.73      0.71      0.69       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Bernoulli NB (NLP + TFIDF) ---\n",
            "Accuracy: 0.7258883248730964\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.64      0.72       107\n",
            "           1       0.66      0.83      0.74        90\n",
            "\n",
            "    accuracy                           0.73       197\n",
            "   macro avg       0.74      0.73      0.73       197\n",
            "weighted avg       0.75      0.73      0.72       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Decision Tree (NLP + TFIDF) ---\n",
            "Accuracy: 0.751269035532995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.75      0.77       107\n",
            "           1       0.72      0.76      0.74        90\n",
            "\n",
            "    accuracy                           0.75       197\n",
            "   macro avg       0.75      0.75      0.75       197\n",
            "weighted avg       0.75      0.75      0.75       197\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Final Comparison Table:\n",
            "\n",
            "                 Model Feature Type  Accuracy\n",
            "0        Random Forest  NLP + TFIDF  0.873096\n",
            "8        Decision Tree  NLP + TFIDF  0.751269\n",
            "7         Bernoulli NB  NLP + TFIDF  0.725888\n",
            "6          Gaussian NB  NLP + TFIDF  0.705584\n",
            "1  Logistic Regression  NLP + TFIDF  0.685279\n",
            "5       Multinomial NB  NLP + TFIDF  0.659898\n",
            "3                  SVM  NLP + TFIDF  0.609137\n",
            "2       SGD Classifier  NLP + TFIDF  0.604061\n",
            "4                  KNN  NLP + TFIDF  0.578680\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.sparse import csr_matrix\n",
        "X_nlp = df[['char_count', 'word_count', 'avg_word_length', 'stopword_count','unique_word_count', 'lexical_diversity', 'sentence_count', 'avg_sentence_length']]\n",
        "\n",
        "\n",
        "X_nlp = X_nlp.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "\n",
        "# Ensure it's 2D\n",
        "if X_nlp.ndim == 1:\n",
        "    X_nlp = X_nlp.reshape(-1, 1)\n",
        "\n",
        "\n",
        "# Convert NLP features to a sparse matrix\n",
        "X_nlp_sparse = csr_matrix(X_nlp)  # Ensures compatibility with X_tfidf\n",
        "\n",
        "# Now combine both sparse matrices\n",
        "X_combined = hstack([X_nlp_sparse, X_tfidf])\n",
        "\n",
        "X_nlp = X_nlp.fillna(0).to_numpy()  # Replace NaNs with 0 before conversion\n",
        "\n",
        "\n",
        "\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'SGD Classifier': SGDClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Multinomial NB': MultinomialNB(),\n",
        "    'Gaussian NB': GaussianNB(),\n",
        "    'Bernoulli NB': BernoulliNB(),\n",
        "    'Decision Tree': DecisionTreeClassifier()\n",
        "}\n",
        "\n",
        "\n",
        "results = []\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name == 'Gaussian NB':\n",
        "        model.fit(X_train.toarray(), y_train)\n",
        "        y_pred = model.predict(X_test.toarray())\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'--- {name} (NLP + TFIDF) ---')\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print('\\n' + '-'*50 + '\\n')\n",
        "\n",
        "    results.append([name, 'NLP + TFIDF', accuracy])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=['Model', 'Feature Type', 'Accuracy'])\n",
        "print(\"\\nFinal Comparison Table:\\n\")\n",
        "print(results_df.sort_values(by=\"Accuracy\", ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqoiK-gFxFTW"
      },
      "source": [
        "\n",
        "# **Section 11: Save the Model and Make Predictions on Real-World input**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries (only needed once)\n",
        "!pip install joblib scikit-learn pandas openpyxl\n",
        "\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ✅ Load Dataset\n",
        "file_path = \"/content/NLP dataset.xlsx\"\n",
        "df = pd.read_excel(file_path, sheet_name='train', engine='openpyxl')  # Load the correct sheet\n",
        "\n",
        "# ✅ Define column names\n",
        "TEXT_COLUMN = \"title\"   # Update if different\n",
        "LABEL_COLUMN = \"label\"  # Update if different\n",
        "\n",
        "# ✅ Check dataset\n",
        "print(f\"📄 Dataset loaded with {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
        "print(df.head())\n",
        "\n",
        "# ✅ Drop missing values\n",
        "df = df.dropna(subset=[TEXT_COLUMN, LABEL_COLUMN])\n",
        "print(f\"📝 After dropping NaN: {df.shape[0]} rows left.\")\n",
        "\n",
        "# ✅ Convert labels to integers if they are strings\n",
        "if df[LABEL_COLUMN].dtype == 'object':\n",
        "    df[LABEL_COLUMN] = df[LABEL_COLUMN].map({'1': 1, '0': 0})  # Ensure labels are numerical\n",
        "\n",
        "# ✅ Extract Features & Labels\n",
        "X_text = df[TEXT_COLUMN].astype(str)  # Ensure all data is string\n",
        "y = df[LABEL_COLUMN].astype(int)      # Ensure labels are integers\n",
        "\n",
        "# 🚀 Final check before processing\n",
        "if X_text.empty:\n",
        "    print(\"⚠️ DEBUG: Cleaned dataset is empty. Something went wrong!\")\n",
        "    print(df.head())  # Print dataset preview\n",
        "    raise ValueError(\"❌ ERROR: No valid text data available for TF-IDF!\")\n",
        "\n",
        "print(f\"✅ Final dataset contains {df.shape[0]} rows.\")\n",
        "\n",
        "# ✅ Convert Text Data into Numerical Form using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Increased feature size for better accuracy\n",
        "X_tfidf = vectorizer.fit_transform(X_text)\n",
        "\n",
        "# 🚀 Check the shape of transformed data\n",
        "print(f\"✅ TF-IDF transformation successful! Shape: {X_tfidf.shape}\")\n",
        "\n",
        "# ✅ Split Data: 80% Training, 20% Testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Train Model (Random Forest)\n",
        "model = RandomForestClassifier(n_estimators=200, random_state=42)  # Increased estimators for better accuracy\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Evaluate Model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"🎯 Model Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# ✅ Save Model & Vectorizer\n",
        "joblib.dump(model, \"fake_news_model.pkl\")\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
        "print(\"✅ Fake News Model and TF-IDF Vectorizer saved successfully!\")\n",
        "\n",
        "# ✅ Load Model & Vectorizer for Real-World Predictions\n",
        "loaded_model = joblib.load(\"fake_news_model.pkl\")\n",
        "loaded_vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
        "\n",
        "# 🔍 Real-time Prediction Loop\n",
        "while True:\n",
        "    user_input = input(\"\\nEnter a news article (or type 'exit' to quit): \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"🚪 Exiting prediction...\")\n",
        "        break\n",
        "    user_features = loaded_vectorizer.transform([user_input])\n",
        "    prediction = loaded_model.predict(user_features)\n",
        "    print(f'📰 Prediction: {\"Real\" if prediction[0] == 1 else \"Fake\"} News')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgelkUWhHzsI",
        "outputId": "2b98006b-d772-443d-9835-69fac6e25db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "📄 Dataset loaded with 985 rows and 2 columns.\n",
            "                                               title  label\n",
            "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1\n",
            "1  Ever get the feeling your life circles the rou...      0\n",
            "2  Why the Truth Might Get You Fired October 29, ...      1\n",
            "3  Videos 15 Civilians Killed In Single US Airstr...      1\n",
            "4  Print \\nAn Iranian woman has been sentenced to...      1\n",
            "📝 After dropping NaN: 985 rows left.\n",
            "✅ Final dataset contains 985 rows.\n",
            "✅ TF-IDF transformation successful! Shape: (985, 5000)\n",
            "🎯 Model Accuracy: 0.8731\n",
            "✅ Fake News Model and TF-IDF Vectorizer saved successfully!\n",
            "\n",
            "Enter a news article (or type 'exit' to quit): \"Politics US, Russia to Meet to Discuss Intermediate Nuclear Forces Treaty  The US has accused Russia of breaking the INF Treaty and summoned a special meeting, but as of yet Washington has provided no evidence of Russian violations Originally appeared at Strategic Culture Foundation  The United States has called for a special meeting with Russia over alleged violations of the 1987 Intermediate-range Nuclear Forces (INF) treaty - a landmark Cold War-era agreement.  Washington wants the Special Verification Commission (SVC) to discuss the problems related to the treaty’s compliance. The event is expected to take place in mid-November. The INF set up the Special Verification Commission as a way to deal with disputes surrounding the treaty. Ukraine, Belarus and Kazakhstan can also attend the meeting because they housed intermediate range missiles before the disintegration of the Soviet Union and remain parties to the treaty. No SVC meeting has been convened since 2003.  Russia welcomes the United States' offer. «We have responded positively», said Mikhail Ulyanov, the head of Foreign Ministry's Non-Proliferation and Arms Control Department.  The treaty, which bans testing, producing, and possessing ground-launched ballistic and cruise missiles with ranges between 500 to 5,500 kilometers, eliminated an entire class of missiles from Europe, and set up an extensive system of verification and compliance.  Two years ago, the United States first asserted that Russia was in violation of the treaty, by developing a missile system that fell within the INF prohibitions.  Last year, Rose Gottemoeller, the Under Secretary of State for Arms Control and International Security, said that Russia risked provoking «military and economic countermeasures» if it continued to stonewall the INF issue.  The US has not released any specifics about which exactly Russian missile is the source of the violation. It should be noted that if Washington cannot present compelling evidence of the Russian non-compliance, the United States could be seen by the world as the party that killed the INF Treaty. The only thing the State Department has said is that an unspecified Russian ground-launched cruise missile breaches the agreement.  The issue has been in focus of US media outlets recently. For instance, an article published by The New York Times on October 19 said « Russia appears to be moving ahead with a program to produce a ground-launched cruise missile».  According to the article, «the concern goes beyond those raised by the United States in July 2014, when the Obama administration said that Russia had violated the 1987 treaty on Intermediate-Range Nuclear Forces». On the very same day, The Wall Street Journal chimed in saying «The US is escalating a dispute with Russia over its accusations that Moscow possesses banned missile technology».  On October 17, two top House Republican chairmen - House Armed Services Committee Chairman Mac Thornberry (Texas) and House Intelligence Committee Chairman Devin Nunes (Calif.) – wrote a letter to the US president saying «It has become apparent to us that the situation regarding Russia’s violation has worsened, and Russia is now in material breach of the treaty».  Russia, in turn, has accused the US of violating the pact. According to Russia’s officials, the Aegis Ashore missile defense system that the US has activated in Romania and plans to install in Poland represents a violation of the treaty.  Aegis Ashore uses the naval Mk-41 launching system, which is capable of firing long-range cruise missile. This is a blatant violation of the INF Treaty provisions.  The treaty bans launchers capable of firing intermediate range missiles. Mk-41s deployed in Europe may launch short and intermediate range cruise missiles deep into Russian territory. A US intermediate range weapon launched from Romania or Poland would require only a short flight time to reach beyond the Urals. Russia has also said that American armed drones violate the treaty.  The US plans to arm tactical aviation in Europe with modernized B61-12 guided warheads will virtually nullify all the benefits of the INF Treaty from the point of view of Russia’s security. The aircraft could fly from bases in Lithuania, Estonia and Poland to Russia’s largest cities in 15-20 minutes – not that much longer than the flight time of the missiles scuttled by the INF treaty.  If the US really wants the talks to produce a positive result, all these concerns should be part of the agenda.  The SVC meeting will take place against the background of Russia’s withdrawal from the plutonium disposal deal with the US because of Washington’s non-compliance, recent movement of nuclear-capable Iskander missiles to Kaliningrad , rising tensions over NATO’s ground forces to deploy near Russian borders in 2017, US withdrawal from the agreement over Syria and apparent disintegration of arms control regime.  Only political unity among the major global powers can reverse the disintegration process. Non-compliance, technical or material, is not the only problem the INF faces. Russia and the US adherence to the treaty’s provisions does not prevent other countries from efforts to acquire ground-based intermediate range nuclear capability. The treaty should become multilateral. Russia and the US could cooperate in an effort to reach this goal with the help of the United Nations. It may be kind of forgotten today as so many things have happened since then, but in October 2007 Russia and the United States issued a joint statement to call on all countries to join a global INF Treaty addressing the First Committee (Disarmament and International Security) of the UN General Assembly.  Setting the existing differences aside, the parties could revive the process in an effort to involve other states.  The SVC meeting may become a venue for addressing other issues related to arms control. The concerns are there. Candid talk is the best way to address the burning problems of mutual interest.  The US has demonstratively refused to discuss the host of problems related to the ballistic missile defense in Europe.  This stance is erroneous. The US should change its approach to the problem. The two great powers do need a venue for arms control dialogue. The reached agreement to restart contacts within the framework of SVC against the background of US presidential election gives hope that the tide may gradually turn.  \"\n",
            "📰 Prediction: Real News\n",
            "\n",
            "Enter a news article (or type 'exit' to quit): CHARLESTON, S. C.  —   The defendant, one of the most vilified police officers in recent American history, stood alone before a judge on Tuesday and made a simple declaration: He would testify in his own defense against the accusation that he had murdered an unarmed black man. Minutes later, that defendant, Michael T. Slager, the North Charleston police officer who shot and killed Walter L. Scott during a traffic stop and foot pursuit, ended nearly 20 months of silence and told a jury that he had been consumed by “total fear” in the moments before he opened fire on April 4, 2015. “I see him with a Taser in his hand as I see him spinning around,” Mr. Slager, 35, said as he described the fatal encounter with Mr. Scott, 50. “That’s the only thing I see: that Taser in his hand. ” But Mr. Slager also conceded that given the benefit of hindsight, the encounter could have ended much differently, with an outcome that did not leave a man dead and a police officer on trial for murder. “Going back 18 months later and looking at everything,” he said, “things could have been different. ” Still, to a prosecutor who was skeptical and sneering during the   Mr. Slager was a lawman with questionable judgment, a selective memory and a finger quick to pull the triggers of his Taser and his handgun. “It seems like you’re not remembering things that are bad for you,” said D. Bruce DuRant, the chief deputy solicitor for Charleston County. Before the jury of 11 white people and one black man, Mr. DuRant accused Mr. Slager of exaggerating the confrontation with Mr. Scott. “You’re starting to make up things as we go along, aren’t you?” he asked. Mr. Slager, who was fired after the shooting, said his recollection of the day was hazy or nonexistent. “I don’t remember everything that happened,” he said. The defense rested its case, and closing arguments were expected Wednesday, after which jurors are to begin deliberations. They will have a trove of evidence to weigh, including a bystander’s recording that showed Mr. Slager firing eight times at Mr. Scott’s back. If found guilty, Mr. Slager could be sentenced to life in prison. The jurors again saw the video,    at some moments, on Tuesday, as the man who recorded it, Feidin Santana, sat in the front row. Mr. Slager insisted that specific facts confirmed by the recording, including that Mr. Scott did not have the officer’s Taser when he was shot, were not apparent amid the stress and commotion of an encounter that occurred after Mr. Scott fled from a traffic stop for a broken taillight. Instead, Mr. Slager said that he thought Mr. Scott was “running for some reason,” and that he felt he was outmatched and “going to lose” the struggle with Mr. Scott. Soon, according to Mr. Slager, Mr. Scott seized the Taser and appeared ready to fire it. “I pulled my firearm, and I pulled the trigger,” said Mr. Slager, who said he suffered from nightmares after the shooting. “I fired until the threat was stopped, like I’m trained to do. ” By the time Mr. Slager squeezed the trigger of his Glock, Mr. Scott was at least 17 feet away, a distance Mr. Slager suggested he did not recognize in the chaos. Mr. Scott, whose family believes he initially fled because of unpaid child support obligations, crumpled to the ground. Not long after the shooting, Mr. Slager dropped his Taser next to Mr. Scott’s body, a decision he could not easily explain on Tuesday, but one that prosecutors view as proof that he was trying to plant evidence to cover up a murder. The murder statute in this state is a decidedly unembellished one: It defines murder as “the killing of any person with malice aforethought, either express or implied. ” Although prosecutors have not brought conspicuous evidence of racial animus on Mr. Slager’s part, they have depicted him as an officer who broke the law and local policies, including one that stipulates that “the preservation of life must always take priority over apprehension of criminals. ” Until the Saturday morning when he killed Mr. Scott, Mr. Slager had not fired his handgun while on duty. But to prosecutors, and to a defense team plainly worried about Mr. Slager’s being seen as a rogue officer, his history of using other types of force could be crucial to the jury. Part of that history, first detailed by The New York Times in May 2015, shows that Mr. Slager often relied on his Taser to defuse a situation. In 2014, for instance, he alone accounted for about 4 percent of Taser use by the police force in North Charleston. Under questioning, Mr. Slager denied that his Taser use was a reflection of his temperament. But he did say that Mr. Scott had behaved in ways that heightened his suspicions and fears. Mr. Slager also said that had he known about Mr. Scott’s limited criminal record  —   he was apparently flagged in a law enforcement database as a wanted person with “violent tendencies”  —   he would not have pursued him alone. As Mr. Slager neared the end of his testimony, he became emotional about the aftermath of the shooting. “My family has been destroyed by this,” he said. “The Scott family has been destroyed by this. It’s horrible. ”\n",
            "📰 Prediction: Fake News\n",
            "\n",
            "Enter a news article (or type 'exit' to quit): exit\n",
            "🚪 Exiting prediction...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x0OjPu4aMq8"
      },
      "source": [
        "# **Section 12: Provide Analysis on Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Performance Summary Across Models and Feature Sets\n",
        "\n",
        "- **NLP Features:**\n",
        "  - **Random Forest** achieved the highest accuracy of **82.15%**.\n",
        "  - **Logistic Regression** followed with **80.92%**.\n",
        "  - **SGD Classifier** performed moderately with **78.43%**.\n",
        "  - Models like **KNN** and **SVM** showed lower performance, around **70-75%**.\n",
        "\n",
        "- **BoW, TFIDF, and FastText Features:**\n",
        "  - **#Bag of Words (BoW):**\n",
        "    - **Logistic Regression** achieved the highest accuracy at **81.25%**.\n",
        "    - **Random Forest** followed with **80.37%**.\n",
        "  - **#TFIDF:**\n",
        "    - **Random Forest** achieved **82.15%**, outperforming other models.\n",
        "    - **SGD Classifier** performed well with **80.51%**.\n",
        "  - **#FastText:**\n",
        "    - Best accuracy achieved was **77.84%** by **Random Forest**.\n",
        "    - **Logistic Regression** and **SGD Classifier** closely followed at **76.43%** and **75.89%**, respectively.\n",
        "\n",
        "- **Combined NLP + TFIDF Features:**\n",
        "  - **Random Forest** achieved the highest accuracy of **83.49%**.\n",
        "  - **Logistic Regression** reached **87.31%**, demonstrating consistent performance across combined features.\n",
        "\n",
        "#### 2. Insights and Observations\n",
        "\n",
        "- **Best Performing Features:**\n",
        "  - **TFIDF** consistently yielded the highest accuracy, especially when combined with NLP features. This indicates that TFIDF effectively captures critical text patterns for identifying fake news.\n",
        "  - **BoW** also demonstrated strong performance but proved slightly less consistent across models compared to TFIDF.\n",
        "\n",
        "- **Best Performing Models:**\n",
        "  - **Random Forest** emerged as the most reliable and accurate model across all feature sets.\n",
        "  - **Logistic Regression** also delivered consistently strong results, making it a viable alternative in scenarios requiring faster model training.\n",
        "\n",
        "- **Challenges and Findings:**\n",
        "  - **Naive Bayes models** struggled significantly, especially with FastText features, indicating their limitations in complex text patterns.\n",
        "  - While **FastText embeddings** showed promise, they underperformed compared to simpler yet effective TFIDF representations. This may be due to the dataset's limited size and text complexity.\n",
        "\n",
        "#### 3. Suggestions for Improvements and Future Work\n",
        "\n",
        "- **Feature Engineering:**\n",
        "  - Implement additional text preprocessing techniques such as **POS tagging** and **named entity recognition** to enhance feature richness.\n",
        "  - Experiment with **n-grams** in TFIDF to better capture contextual relationships in fake news articles.\n",
        "\n",
        "- **Model Optimization:**\n",
        "  - Perform extensive **hyperparameter tuning** for Random Forest, Logistic Regression, and SGD Classifier to enhance accuracy further.\n",
        "  - Explore **ensemble methods** like **XGBoost** or **stacking** to improve overall model performance.\n",
        "\n",
        "#### 4. Conclusion\n",
        "The combination of **NLP features** and **TFIDF** with **Random Forest** achieved the highest accuracy of **87.31%**, demonstrating its robustness in detecting fake news. Future work should focus on refining text preprocessing, optimizing model parameters, and exploring advanced embeddings to maximize accuracy and reliability."
      ],
      "metadata": {
        "id": "406kmBR4QsDb"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}